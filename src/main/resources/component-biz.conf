product {
    modules {
        sirius-biz {
            version = "${project.version}"
            build = "${build.number}"
            date = "${timestamp}"
            vcs = "${build.vcs.number}"
        }
    }
}

# sirius-biz provides a multitude of frameworks for different use-cases
# and implements them using different databases. Therefore by default
# all frameworks are disabled and have to be enabled by the application.
sirius.frameworks {

    # A JDBC based user-manager which supports multi-tenant
    # applications
    biz.tenants    = false

    # A JDBC based framework for letting a user map codes to
    # text values
    biz.code-lists = false

    # Utilizes Elasticsearch to store all recorded logs, incidents,
    # audit logs and mails
    biz.protocols  = false

    # Provides a change log for all entities which include a JournalData
    biz.journal    = false

    # Provides an ID Generator which can either use MongoDB or JDBC
    # to generate sequences of unique IDs
    biz.sequences  = false

    # Provides distributed locks based on either the JVM, Redis or JDBC
    biz.locks      = false

    # Provides a object store like API for storing files. This can either use
    # the file system or other storage facilities.
    biz.storage    = false

    # Provides a rate-limiting / firewall which is either based on Redis.
    biz.isenguard  = false
}

# Place the local address of the node here, i.e. http://192.168.0.1
# If no address is given, we use the local address determined by the system
# (using: InetAddress.getLocalHost().getHostAddress()) - however, in some
# environments like Docker, this might yield an inappropriate address.
#
# This address has to be reachable from all other cluster nodes.
sirius.nodeAddress = ""

# Contains settings for the built-in firewall and rate-limiting facility
isenguard {
    # Determines which limiter is used. By default we use a "smart" strategy,
    # which uses "redis" is available and otherwise switches to the "noop" limiter.
    limiter = "smart"

    # If the "Redis" limiter is used, the given redis database is used to store
    # the counters and blocked IPs. By default we use the "system" database,
    # which is the default redis.
    redisName = "system"

    # Contains an interval and limit per interval for each realm.
    # Note that the realm "http" is used to limit all notable
    # HTTP calls.
    limit {
        # Specifies the defaults for all realms unless noted otherwise.
        # By default IsenGuard is turned off.
        default {
            interval = 10m
            limit = 0
        }

        # Specifies the constraints for all HTTP requests. By default this
        # is turned off, as there is no way of knowing the usage pattern
        # of a specific application.
        http {
            interval = 0
            limit = 0
        }

        # Specifies the constraints for negative AuditLog events (wrong password etc).
        # Once this limit is hit, the calling IP will be blocked for ten minutes.
        security {
            interval = 2m
            limit = 50
        }
    }

}

health.limits {
    # If there is any lock held, we will report this - but there is no
    # sane limit how many locks can be considered healthy / unhealty
    locks-count.gray  = 1
    locks-count.warning  = 0
    locks-count.error = 0

    # We start to warn as soon as we encounter one long running lock
    # (held for at least 30min). As this can still be quite alright
    # we do not consider this critical (red)
    locks-long-running.gray  = 0
    locks-long-running.warning  = 1
    locks-long-running.error = 0
}

async {
    # Defines the maximal number of concurrent tasks executed for the
    # Distributed Tasks framework.
    executor.distributed-tasks {
        poolSize = 8

        # Having a queue would be pointless, as the WorkLoaderLoop only
        # tries to keep the available executors running but will not
        # schedule additional work.
        queueLength = 0
    }

    distributed {
        # Configures the nature of the queues used to distribute tasks.
        queues {
            # Each queue needs to suppliy the following settings
            # example {
                # Contains the concurrency token to control node-local parallelism
                # concurrencyToken = SomeToken

                # Determines if the queue is prioritized or a FIFO queue
                # prioritized = false

                # For prioritized queues the penalty should approximately be
                # equal to the expected runtime of an average task. This time is
                # used to compute the effective execution priority once a task is
                # scheduled.
                # penaltyTime = 1 minute
            # }

            jobs {
                concurrencyToken = ""
                prioritized = true
                penaltyTime = 1h
            }
        }

        # Configures concurrency tokens which are semaphores on each node and
        # control local parallelism. Note that a single token can be shared by
        # multiple queues.
        concurrency {
            # SomeToken = 4
        }
    }
}

# Provides a cluster wide controller for executing background jobs.
# NeighborhoodWatch uses Redis locks and timestamps to control the
# execution of background jobs across a cluster of nodes.
# Per job one for the following settings can be set:
# LOCAL    - the jobs runs on this node independently of the cluster
# CLUSTER  - the job may run on this node, but only on one node within the cluster at once
# DISABLED - the job is disabled on this node
orchestration {
    loop-crunchlog-writeback = LOCAL
    loop-DelayLine = LOCAL
    loop-event-processor = LOCAL
    loop-delay-line = LOCAL
    loop-distributed-tasks-work-loader = LOCAL
    loop-storage-cleanup = CLUSTER
    loop-redis-limiter-cleanup = CLUSTER
    task-protocols-cleaner = CLUSTER
    task-logs-cleanup = LOCAL
    task-storage-cleaner = LOCAL
}

# Controls the execution of the daily task in which protocols and journals are deleted based on the given settings...
timer.daily.protocols-cleaner = 2

# Controls the storage duration of protocol entries
protocols {
    keep-logs = 30 days
    keep-incidents = 30 days
    keep-mails = 365 days
    keep-journal = 1000 days
    keep-neutral-audit-logs = 30 days
    keep-negative-audit-logs = 180 days
}

# Controls the execution of the daily task which cleans up outdated files in the storage system...
timer.daily.storage-cleaner = 3

jobs {
    # Max amout of logs to keep
    # Note that the system will not delete logs which are younger than "keep-logs-days"
    max-logs = 10

    # The number of days a job log is kept, even if this job has more than "max-logs" protocols
    keep-logs-days = 14
}

content.extensions {
    templates-page-menu-left {
        settings {
            priority = 1000
            template = "templates/wondergem/menu-left-settings.html.pasta"
        }
    }

    templates-menu-settings {
        code-lists {
            priority = 100
            template = "templates/codelists/settings-menu-code-lists.html.pasta"
        }
    }

    templates-page-menu-right {
        user {
            priority = 500
            template = "templates/wondergem/menu-right-user.html.pasta"
        }
    }

    templates-user-menu {
        tenants {
            priority = 100
            template = "templates/tenants/user-menu-tenants.html.pasta"
        }
    }

    templates-page-footer {
        stored-object-uploader {
            priority = 100
            template = "templates/storage/stored-object-uploader.html.pasta"
        }
    }

}

code-lists {
    default {
        autofill = true
    }

    salutations {
        name = "Salutations"
        description = "Contains all salutations known to the system"
    }

    countries {
        name = "Countries"
        description = "Contains all countries known to the system. A RegEx can be supplied as additional value which is used to verify ZIP codes"
    }
}

storage {

    # Defines the base directory when storing buckets in disk.
    baseDir = "data/storage"

    # If using ImageMagick, consider a command like:
    # "convert ${src} -resize ${width}x${height}> -quiet -quality 89 -format ${imageFormat} -strip -colorspace RGB -background white ${extend} -flatten ${dest}"
    conversionCommand=""

    # Option for the conversion command to extend the image to a minimum size
    extendOption = "-gravity center -extent ${extendWidth}x${extendHeight}<"

    # Defines all buckets known to the system.
    buckets {
        default {
            # Defines the permission required to view the bucket in the management UI.
            permission = "permission-manage-files"

            # Determines if an object (file) can be created via the management UI.
            canCreate = false

            # Determines if an object (file) can be edited via the management UI.
            canEdit = false

            # Determines whether a search in a bucket should always use a like constraint.
            alwaysUseLikeSearch = false

            # Determines if an object (file) can be deleted via the management UI.
            canDelete = false

            # Determines if objects are automatically removed after N days. 0 means disabled.
            deleteFilesAfterDays = 0

            # Determines the storage engine used for the bucket.
            engine = "fs"
        }

        # A work directory / bucket is provided per tenant and can be used to in- and output files.
        # This is also visible in the built-in virtual file system (FTP server) to upload and download files.
        # To limit the number of files in this directory, old files (older than 30 days) are automatically removed.
        # Therefore this should not be used for permanent storage.
        work {
            canCreate = true
            canEdit = true
            canDelete = true
            deleteFilesAfterDays = 30
        }

        # Provides a temporary storage space which is automatically maintained (files are deleted after 30 days).
        tmp {
            permission = "permission-manage-admin-files"
            canCreate = true
            canEdit = true
            canDelete = true
            deleteFilesAfterDays = 30
        }

    }

}

# Contains settings for the virtual file system.
vfs {

    # Defines the settings of the built-in FTP server.
    ftp {
        # Specifies the port to listen on. Use 0 to disable the server or 21 to run it on the common FTP port.
        port = 0

        # Specifies the IP address to bind to. Leave empty to use all IP addresses.
        bindAddress = ""

        # Specifies the max. login failures before disconnecting.
        maxLoginFailures = 5

        # Specifies the max. number of concurrent clients.
        maxClients = 100

        # Specifies the max. number of threads to utilize.
        maxThreads = 10

        # Specifies the idle timeout for connections.
        idleTimeout = 10m

        # Specifies the max. connections per IP.
        maxConnectionsPerIp = 5

        # Specifies the JKS keystore to use for FTPS.
        keystore = ""

        # Specifies the keystore password.
        keystorePassword = ""

        # Specifies the key alias to use.
        keyAlias = ""

        # Determines if FTPS should be forced or not.
        forceSSL = false
    }
}

# Provides credentials for the S3 compatible stores managed by ObjectStores.
s3 {

    stores {

        # Provides the default configuration shared by all stores.
        default {
            accessKey = ""
            secretKey = ""
            endPoint = ""
            bucketSuffix = ""
            pathStyleAccess = true

            # Specifies the signer to use. Leave empty to use the standard signer of the
            # current AWS SDK.
            signer = ""
            # Use the following setting for CEPH stores:
            # signer = "S3SignerType"
        }

        # By default a "system" store is used if no other name is given.
        # An application should provide a configuration for this store if ObjectStores are used.
        system {

        }
    }

}

security {

    passwordMinLength = 4
    passwordSaneLength = 6

    # Specifies for how long generated passwords should be displayed.
    showGeneratedPasswordFor = 5 days

    scopes.default {
        manager = "tenants"
        system-tenant = "1"
        loginCookieTTL = 90 days
    }

    permissions {
        permission-manage-system        : "Required for system tenant user accounts to manage system settings"
        permission-manage-tenants       : "Required to manage tenants of the system"
        permission-manage-user-accounts : "Required to manage user accounts"
        permission-manage-code-lists    : "Required to manage code lists"
        permission-system-protocols     : "Required to view protocols like logs, errors, mails, all audit logs"
        permission-system-cluster       : "Required to view and manage the cluster state"
        permission-audit-logs           : "Required to view audit logs for the own tenant"
        permission-system-journal       : "Required to view the system journal"
        permission-select-tenant        : "Required to switch to another tenant"
        permission-select-user-account  : "Required to switch to another user"
        permission-tasks                : "Required to view all managed tasks"
        permission-manage-jobs          : "Required to edit and create jobs"
        permission-execute-jobs         : "Required to execute jobs"
        permission-manage-files         : "Required to manage well known buckets in the storage system"
        permission-manage-admin-files   : "Required to access administrative buckets in the storage system"
    }

    roles = [ "user-administrator", "administrator", "jobs-manager", "jobs-execution", "file-manager" ]

    tenantPermissions = [
        "feature-provide-jobs"
    ]

    profiles {

        flag-system-tenant {
            permission-manage-tenants = true
            permission-manage-code-lists = true
            permission-system-protocols = true
            permission-system-cluster = true
            permission-system-journal = true
            permission-system-console = true
            permission-system-timing = true
            permission-system-scripting = true
            permission-system-notify-state = true
            permission-tasks = true
            feature-provide-jobs = true
        }

        user-administrator {
            permission-manage-user-accounts = true
            permission-select-user-account = true
            permission-manage-system = true
        }

        administrator {
            permission-select-tenant = true
            permission-execute-jobs = true
            permission-manage-jobs = true
            permission-view-scope-default-config = true
            permission-manage-jobs = true
            permission-manage-files = true
            permission-manage-admin-files = true
            permission-system-audit-logs = true
        }

        jobs-manager {
            permission-manage-jobs = true
        }

        jobs-execution {
            permission-execute-jobs = true
        }

        file-manager {
            permission-manage-files = true
        }
    }

}

# Specifies cache sizes used by the biz platform
cache {

    tenants-users {
        maxSize = 100
        ttl = 1 hour
    }

    tenants-roles {
        maxSize = 100
        ttl = 1 hour
    }

    tenants-children {
        maxSize = 256
        ttl = 1 hour
    }

    tenants-tenants {
        maxSize = 32
        ttl = 1 hour
    }

    tenants-configs {
        maxSize = 100
        ttl = 1 hour
    }

    storage-object-metadata {
        maxSize = 4096
        ttl = 1 hour
    }

    virtual-objects {
        maxSize = 4096
        ttl = 1 hour
    }

}

# Specifies thread pools used by the biz platform
async.executor {
    # This work queue is shared by all transfer managers across all object stores and
    # used for multipart up- and downloads.
    s3 {
        poolSize = 10
        queueLength = 0
    }
}

# By default we use the smart lock manager. This detects the presence of redis and uses cluster-wide locks
# or otherwise uses fast local locks within the JVM. to enforce local locks, use "java".
# Another approach for clusters without Redis is using an SQL Database to implement locks distributed locks
# which is available via "sql" (SQLLockManager).
locks.manager = "smart"

# Determines how "Sequences" are stored and computed. By default a "smart" strategy is used which either
# checks if a "sql" database or a "mongo" database is ready and picks the right strategy. If both are
# available the effective startegy can be determined by setting an explicit value here.
sequences.strategy = "smart"
